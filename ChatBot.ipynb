{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb423703-5b4b-449c-b010-f3f9be1cc870",
   "metadata": {},
   "source": [
    "# CHATBOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7107965e-57e3-43fa-9048-295ccc830563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "#import the LLM APIs\n",
    "import ollama\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "import google.generativeai\n",
    "\n",
    "\n",
    "import gradio as gr  \n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "GOOGLE_API_KEY=os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81a8e80c-d13b-402b-bafe-8cf7e5d3ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openAI = OpenAI()\n",
    "clade= anthropic.Anthropic()\n",
    "#google = generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c47e980-6786-456e-9925-7c85d3ed373e",
   "metadata": {},
   "source": [
    "# Classes and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ce5ba07-bed8-4e0b-8ca6-7c9313228b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "class Website:\n",
    "    def __init__ (self,url):\n",
    "        ''' \n",
    "        Create this website object from the given url using BwautifulSoup\n",
    "        '''\n",
    "\n",
    "        self.url=url\n",
    "        response = requests.get(url,headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No Title found\"\n",
    "        for irrelevant in soup.body(['style', \"scripts\", \"img\",\"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text =soup.body.get_text(separator=\"\\n\",strip=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0b201165-73e8-4901-b252-3a8806ade47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateLLAMAResponse_stream(text):\n",
    "    OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "    HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "    MODEL = \"llama3.2\"\n",
    "    messages = [{\"role\":\"system\", \"content\":\"You are an assistant that anal yzes the contents of a website \\\n",
    "                    and provides a short summary, ignoring text that might be navigation related. \\\n",
    "                    Respond in markdown.\"},\n",
    "                {\"role\":\"user\",\"content\":f'''Analyse the given text in triple ticks carefully and give a crips summary ```{text}```'''}]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages \n",
    "    }\n",
    "\n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "    \n",
    "    return response.json()['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfd868-26e5-4812-9023-92a311ff7eb6",
   "metadata": {},
   "source": [
    "## Functions for LLAMA(Local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d5e7d5fd-cb05-40de-9de4-780e6fddb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateLLAMAResponse(text):\n",
    "    OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "    HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "    MODEL = \"llama3.2\"\n",
    "    messages = [{\"role\":\"system\", \"content\":\"You are an assistant that anal yzes the contents of a website \\\n",
    "                    and provides a short summary, ignoring text that might be navigation related. \\\n",
    "                    Respond in markdown.\"},\n",
    "                {\"role\":\"user\",\"content\":f'''Analyse the given text in triple ticks carefully and give a crips summary ```{text}```'''}]\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages\n",
    "    }\n",
    "\n",
    "    response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "    \n",
    "    return response.json()['message']['content']\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb51363-c485-4ad2-bcd4-376b79ab1f65",
   "metadata": {},
   "source": [
    "## Functions for Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "4668b432-0512-4698-84fb-607dfb6fdf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Google_Response(messages):\n",
    "   \n",
    "    gemini_via_openai_client = OpenAI(\n",
    "        api_key=GOOGLE_API_KEY, \n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    )\n",
    "    \n",
    "    response = gemini_via_openai_client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=messages \n",
    "         \n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4514d61c-d076-4c09-bafe-a8f1c37eacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateGoogleResponse(messages):\n",
    "   \n",
    "    gemini_via_openai_client = OpenAI(\n",
    "        api_key=GOOGLE_API_KEY, \n",
    "        base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "    )\n",
    "    \n",
    "    response = gemini_via_openai_client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=messages \n",
    "         \n",
    "    )\n",
    "    return response.choices[0].message.content \n",
    "    #print(response) \n",
    "    #yield response.choices[0].delta.content\n",
    "    #return response.choices[0].message.content \n",
    "    #if stream==False:\n",
    "     #   return response.choices[0].message.content \n",
    "    #else:\n",
    "     #   yield response.choices[0].delta.content\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6cb8dbc4-669d-4470-a6fb-a2539fc4a5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you're playing with your toys, and you have to decide: should you build a big castle, or should you have a spaceship adventure?  That's a question, right?\n",
      "\n",
      "This sentence, \"To be or not to be. That, my dear, is the question,\" is like that, but it's a much bigger question!  \"To be\" means to keep living, and \"not to be\" means to stop living, to die.\n",
      "\n",
      "So it's asking: \"Should I keep living, or should I die? That's the big question!\"  It's a question someone might ask when they're feeling very sad or unsure about life.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text =\"To Be or not to be. That my dear is the question.\"\n",
    "\n",
    "messages = [{\"role\":\"system\", \"content\":\"You are an assistant that explains the phrase to a 5 year old kid.\"},\n",
    "                {\"role\":\"user\",\"content\":f'''Analyse the given text in triple ticks carefully and give the explanation ```{text}```'''}]\n",
    "\n",
    "response= GenerateGoogleResponse(messages,False)\n",
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d42dc6-ff52-4fc9-8044-6657d65a16be",
   "metadata": {},
   "source": [
    "## Functions for OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e7e29ef8-314c-404d-b84c-588a4fea8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateOpenAIResponse_stream(messages):\n",
    "    openAI = OpenAI()\n",
    "    stream= openAI.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", \n",
    "            messages=messages,\n",
    "            stream=True)\n",
    "    result =\"\"\n",
    "    print(\"Received response from GPT\")\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        #print(result)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "308bde9c-cff7-4332-9281-fc47eeefca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_OpenAI_Response(messages,tools,stream=False):\n",
    "    openAI = OpenAI()\n",
    "    response= openAI.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", \n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            stream=stream)\n",
    "     \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "e065f3bf-e7cd-4c70-badd-2d9cf4b2d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateOpenAIResponse(messages,stream):\n",
    "    openAI = OpenAI()\n",
    "    response= openAI.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\", \n",
    "            messages=messages,\n",
    "            stream=stream)\n",
    "     \n",
    "    print(\"Received response from GPT\")\n",
    "     \n",
    "    if stream==False:\n",
    "        return response.choices[0].message.content \n",
    "    else:\n",
    "        yield response.choices[0].delta.content   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a888d6b-3db1-401a-bb06-4f7d94d02084",
   "metadata": {},
   "source": [
    "## Functions to summarise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b759793e-4a4f-498f-a32e-98b26f8e932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_LLM_Model(model, messages):\n",
    "    if model==\"GPT\":\n",
    "        print(\"Calling GPT\")\n",
    "        response = GenerateOpenAIResponse(messages)\n",
    "        print(response)\n",
    "    elif model ==\"LLAMA\":\n",
    "        response = GenerateLLAMAResponse(messages)\n",
    "    elif model ==\"GEMINI\":\n",
    "        response = GenerateGoogleResponse(messages)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "eb540567-cf22-483a-a36b-c42a63952314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise (model,text):\n",
    "    #webText =text #Website(url)\n",
    "    \n",
    "    messages = [{\"role\":\"system\", \"content\":\"You are an assistant that anal yzes the contents of a website \\\n",
    "                    and provides a short summary, ignoring text that might be navigation related. \\\n",
    "                    Respond in markdown.\"},\n",
    "                {\"role\":\"user\",\n",
    "                 \"content\":f'''Analyse the given text in triple ticks carefully and \n",
    "                 give a crips summary ```{text}```'''}]\n",
    "\n",
    "    \n",
    "    return call_LLM_Model(model, messages)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688a8738-b322-4c7f-95e9-1a4e34d9dabb",
   "metadata": {},
   "source": [
    "## Functions to summarise websites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "4471b471-5862-4462-a735-dc65e42077c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_webSite (model,url):\n",
    "    webText =Website(url)\n",
    "    \n",
    "    messages = [{\"role\":\"system\", \"content\":\"You are an assistant that analyses the contents of a website \\\n",
    "                    and provides a short summary, ignoring text that might be navigation related. \\\n",
    "                    Respond in markdown.\"},\n",
    "                {\"role\":\"user\",\n",
    "                 \"content\":f'''Analyse the given text in triple ticks carefully and \n",
    "                 give a crips summary ```{webText.text}```'''}]\n",
    "\n",
    "    return call_LLM_Model(model, messages)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e829f91b-07b2-444f-9d38-42a58ed82731",
   "metadata": {},
   "source": [
    "# Generate Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "28c343ff-2b8b-47ab-91b2-0fdbd89e49ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To set dark mode\n",
    "force_dark_mode=\"\"\"\n",
    "function refresh(){\n",
    "    const url = new URL(window.location)\n",
    "    if (url.searchParams.get('__theme')!=='dark'){\n",
    "        url.searchParams.set('__theme','dark')\n",
    "        window.location.href = url.href\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e2646-a2a4-4885-8c77-64964262975c",
   "metadata": {},
   "source": [
    "## Select Model and summarise text (without Streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d2fa83d5-b19f-4a90-8aed-fe536524d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7897\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7897/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with inputs and outputs\n",
    "\n",
    "view =gr.Interface (\n",
    "    fn=summarise,\n",
    "    inputs =[\n",
    "        gr.Dropdown(['GPT','LLAMA','GEMINI','CLAUDE'], label=\"Select the model\", value=\"GEMINI\"),\n",
    "        gr.Textbox(label=\"Text to summarise\", lines =10)      \n",
    "    ],\n",
    "    outputs =[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode =\"never\",\n",
    "    js=force_dark_mode\n",
    ")\n",
    "\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf58ed53-6d3b-4af1-8e89-1de3f28cf2f7",
   "metadata": {},
   "source": [
    "## Summarise WebSites (with Streaming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "31f5d53c-b303-485a-a162-5d80c6494fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7899\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7899/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with inputs and outputs\n",
    "\n",
    "view =gr.Interface (\n",
    "    fn=summarise_webSite,\n",
    "    inputs =[\n",
    "        gr.Dropdown(['GPT','LLAMA','GEMINI','CLAUDE'], label=\"Select the model\", value=\"LLAMA\"),\n",
    "        gr.Textbox(label=\"Company URL\", lines =1)      \n",
    "    ],\n",
    "    outputs =[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode =\"never\",\n",
    "    js=force_dark_mode\n",
    ")\n",
    "\n",
    "view.launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6dacc7-269e-42e9-96a8-cdfa0ed500b5",
   "metadata": {},
   "source": [
    "## AI Agent for Aurlines FLight Booking (CHATBOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3648ac9e-8e4e-4897-96a4-d813f5786c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "464c25bf-a4b6-46e8-82a4-d58e13037e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  chat(message,history):\n",
    "    messages=[{\"role\":\"system\", \"content\":system_message}] + history +  [{\"role\":\"user\", \"content\":message}]\n",
    " \n",
    "    return GenerateGoogleResponse(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c0a5f3f7-ccf9-41c7-ae38-30354c098275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7903\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7903/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#with inputs and outputs\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8c62fa-d6a5-4630-964f-54a2bd355bff",
   "metadata": {},
   "source": [
    "### Using Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "700d70cd-087c-4933-9e92-a379aea86f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f8f555ce-f520-4f84-b9c7-8a2cd595b22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "7cd7be9e-cc81-490e-a492-b47f3ff42d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "93859060-0d27-4ece-be79-8a3426a75935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is included in a list of tools:\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "972808c6-e045-40c2-816e-61461a9bc61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response, city = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b85a710a-b4b7-4ccc-a65a-2429eb2bb1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    city = arguments.get('destination_city')\n",
    "    price = get_ticket_price(city)\n",
    "    response = {\n",
    "        \"role\": \"tool\",\n",
    "        \"content\": json.dumps({\"destination_city\": city,\"price\": price}),\n",
    "        \"tool_call_id\": message.tool_calls[0].id\n",
    "    }\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b10dcb90-4476-4c1e-8e17-078f6dcc5c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "be963765-b93c-4840-952c-9f5acc6cd35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7917\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7917/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for London\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3b8de-da4d-4f7a-a2d2-608cc2ed4687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
