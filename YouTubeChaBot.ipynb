{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#!pip install groq\n",
        "!pip install youtube_transcript_api\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBxlcPoHqM2C",
        "outputId": "cc9387da-e0d3-4222-be05-7036c94a5ff4"
      },
      "id": "IBxlcPoHqM2C",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-1.0.3-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (0.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from youtube_transcript_api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->youtube_transcript_api) (2025.1.31)\n",
            "Downloading youtube_transcript_api-1.0.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3dce0e41-7e9b-4091-a2e5-a643403b3605",
      "metadata": {
        "id": "3dce0e41-7e9b-4091-a2e5-a643403b3605"
      },
      "outputs": [],
      "source": [
        "import groq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2168562-30e3-4cd0-8bbb-6888674930bc",
      "metadata": {
        "id": "a2168562-30e3-4cd0-8bbb-6888674930bc"
      },
      "outputs": [],
      "source": [
        "groq_api_key= os.environ[\"GROQ-API-Key\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "import youtube_transcript_api as YouTubeTranscriptApi\n",
        "from youtube_transcript_api._errors import TranscriptsDisabled\n",
        "#from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "ZkMzl8wApzIX"
      },
      "id": "ZkMzl8wApzIX",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google_api_key = userdata.get('GOOGLE_API_KEY')"
      ],
      "metadata": {
        "id": "swEKVI-vprSL"
      },
      "id": "swEKVI-vprSL",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "bf4f9668-158e-4cb4-9772-470e11b3521f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf4f9668-158e-4cb4-9772-470e11b3521f",
        "outputId": "1135b0a2-7049-4858-c7b0-d5edc23931ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AIzaSyDjgAZ5K1pOYkFJI7xX4nOFlb3LqloQ5-s\n"
          ]
        }
      ],
      "source": [
        "print(google_api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09f21714-ff0d-4157-b424-6b11c7fd0086",
      "metadata": {
        "id": "09f21714-ff0d-4157-b424-6b11c7fd0086"
      },
      "source": [
        "# Step 1 (Indexing)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1a - Read the YouTube transcripts"
      ],
      "metadata": {
        "id": "eeUleSlVraqv"
      },
      "id": "eeUleSlVraqv"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "abeb0d68-b800-46e6-bac8-6fd06808faa5",
      "metadata": {
        "id": "abeb0d68-b800-46e6-bac8-6fd06808faa5"
      },
      "outputs": [],
      "source": [
        "video_id = \"Gfr50f6ZBvo\" # only the ID, not full URL\n",
        "try:\n",
        "    # If you don’t care which language, this returns the “best” one\n",
        "    #transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
        "    transcript_list = YouTubeTranscriptApi.get_transcript(\"Ks-_Mh1QhMc\" ,languages=[ 'en'])\n",
        "    # Flatten it to plain text\n",
        "    transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
        "    #print(transcript)\n",
        "\n",
        "except TranscriptsDisabled:\n",
        "    print(\"No captions available for this video.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8d3c246-07d1-4dc6-9cb9-c208bb9d38b4",
      "metadata": {
        "id": "b8d3c246-07d1-4dc6-9cb9-c208bb9d38b4"
      },
      "source": [
        "# Step 1b - Create chunks using Text splitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f62daee3-8e12-4068-9ddd-8a69dd232b4f",
      "metadata": {
        "id": "f62daee3-8e12-4068-9ddd-8a69dd232b4f"
      },
      "outputs": [],
      "source": [
        " from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "73196d34-bbc6-49b6-ae1e-3a3420c76c84",
      "metadata": {
        "id": "73196d34-bbc6-49b6-ae1e-3a3420c76c84"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "25dc27cd-dccc-4a03-8a76-95514c13b24b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25dc27cd-dccc-4a03-8a76-95514c13b24b",
        "outputId": "de18e36b-fc40-425f-9d6d-83ab66ef412f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"in the elevator, in a bathroom stall, at your desk\\nbehind closed doors. That's what you want to do. Configure your brain\\nto cope the best in that situation. Get your testosterone up.\\nGet your cortisol down. Don't leave that situation feeling\\nlike, oh, I didn't show them who I am. Leave that situation feeling like, I really feel like I got to say\\nwho I am and show who I am. So I want to ask you first, you know,\\nboth to try power posing, and also I want to ask you to share\\nthe science, because this is simple. I don't have ego involved in this.\\n(Laughter) Give it away. Share it with people, because the people who can use it the most are the ones with no resources\\nand no technology and no status and no power. Give it to them\\nbecause they can do it in private. They need their bodies,\\nprivacy and two minutes, and it can significantly change\\nthe outcomes of their life. Thank you. (Applause)\")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "chunks = splitter.create_documents([transcript])\n",
        "print(len(chunks))\n",
        "chunks[24]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1c - Create Embeddings"
      ],
      "metadata": {
        "id": "Gc27U_s7wp9F"
      },
      "id": "Gc27U_s7wp9F"
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install langchain_community\n",
        "#!pip install langchain_openai\n",
        "#!pip install langchain_core"
      ],
      "metadata": {
        "id": "D5FrM5rb4sCZ"
      },
      "id": "D5FrM5rb4sCZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "openai_api_key= userdata.get('OPENAI_API_KEY')\n",
        "print(openai_api_key)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux6wIJrUv0td",
        "outputId": "c58dd62d-402b-4568-b57b-fca48eee3e54"
      },
      "id": "ux6wIJrUv0td",
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", api_key =openai_api_key)\n",
        "vector_store = FAISS.from_documents(chunks, embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "45uuT9oY5xWQ",
        "outputId": "6e2a81a1-85a3-4730-8e35-665d419e500f"
      },
      "id": "45uuT9oY5xWQ",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************aRQA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-fb2ab5284798>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAIEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"text-embedding-3-small\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mopenai_api_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvector_store\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \"\"\"\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         return cls.__from(\n\u001b[1;32m   1045\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, chunk_size)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;31m#       than the maximum context and use length-safe embedding function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_len_safe_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     async def aembed_documents(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36m_get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mbatched_embeddings\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             response = self.client.create(\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_chunk_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invocation_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/embeddings.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;34m\"/embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m         )\n\u001b[0;32m-> 1276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    947\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 949\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    950\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-proj-********************************************************************************************************************************************************aRQA. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "773aa312-3c25-46e8-97ac-2b480fdedfbf",
      "metadata": {
        "id": "773aa312-3c25-46e8-97ac-2b480fdedfbf"
      },
      "source": [
        "# Create ReActAgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03b5cf86-a52a-4829-9f45-089ff725a6f7",
      "metadata": {
        "id": "03b5cf86-a52a-4829-9f45-089ff725a6f7",
        "outputId": "463f95a9-df6c-4b28-bc59-9fb61ced4292"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Anaconda\\anaconda3\\envs\\genailearning\\Lib\\site-packages\\langsmith\\client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer the following questions as best you can. You have access to the following tools:\n",
            "\n",
            "{tools}\n",
            "\n",
            "Use the following format:\n",
            "\n",
            "Question: the input question you must answer\n",
            "Thought: you should always think about what to do\n",
            "Action: the action to take, should be one of [{tool_names}]\n",
            "Action Input: the input to the action\n",
            "Observation: the result of the action\n",
            "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
            "Thought: I now know the final answer\n",
            "Final Answer: the final answer to the original input question\n",
            "\n",
            "Begin!\n",
            "\n",
            "Question: {input}\n",
            "Thought:{agent_scratchpad}\n"
          ]
        }
      ],
      "source": [
        "#pull reach template\n",
        "\n",
        "from langchain import hub\n",
        "prompt = hub.pull(\"hwchase17/react\")\n",
        "print(prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6def6c4f-2796-458a-8d24-3f1b71c5c435",
      "metadata": {
        "id": "6def6c4f-2796-458a-8d24-3f1b71c5c435"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_react_agent, AgentExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfbb074d-2ce1-4f65-b18b-094f42f8844a",
      "metadata": {
        "id": "dfbb074d-2ce1-4f65-b18b-094f42f8844a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb8eb0b7-0b5d-49f0-86c7-3dceb555d9cc",
      "metadata": {
        "id": "cb8eb0b7-0b5d-49f0-86c7-3dceb555d9cc",
        "outputId": "0e99845b-fdd1-4902-fc25-2f78fdd35e16"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'tool_search' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# only creates the logical steps for us\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m react_agent \u001b[38;5;241m=\u001b[39m create_react_agent(llm, [tool_search], prompt)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tool_search' is not defined"
          ]
        }
      ],
      "source": [
        "# only creates the logical steps for us\n",
        "react_agent = create_react_agent(llm, [tool_search], prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ce2489e-a7ef-4512-9e31-1e4eb855c83b",
      "metadata": {
        "id": "0ce2489e-a7ef-4512-9e31-1e4eb855c83b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}