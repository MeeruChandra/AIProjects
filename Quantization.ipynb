{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "29281dc8-f579-4031-b6f1-cafb5dd2ab43",
      "metadata": {
        "id": "29281dc8-f579-4031-b6f1-cafb5dd2ab43",
        "outputId": "c85d4dda-d685-4584-baf6-3ee34df71ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q requests torch bitsandbytes transformers sentencepiece accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
        "import torch"
      ],
      "metadata": {
        "id": "YiadzKaohMvo"
      },
      "id": "YiadzKaohMvo",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "-nGxGM_0iSv6"
      },
      "id": "-nGxGM_0iSv6",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HF_TOKEN= userdata.get(\"HF_TOKEN\")\n",
        "login(HF_TOKEN, add_to_git_credential=True)"
      ],
      "metadata": {
        "id": "DxMARWz3hr0d"
      },
      "id": "DxMARWz3hr0d",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instruct models\n",
        "\n",
        "LLAMA = \"meta-llama/Meta-Llama-3.2-3B-Instruct\"\n",
        "PHI3 = \"microsoft/Phi-3-mini-4k-instruct\"\n",
        "GEMMA2 = \"google/gemma-2-2b-it\"\n",
        "QWEN2 = \"Qwen/Qwen2-7B-Instruct\" # exercise for you\n",
        "MIXTRAL = \"mistralai/Mixtral-8x7B-Instruct-v0.1\" # If this doesn't fit it your GPU memory, try others from the hub"
      ],
      "metadata": {
        "id": "XwjJfaYciNbL"
      },
      "id": "XwjJfaYciNbL",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
        "    {\"role\": \"user\", \"content\": \"Tell a light-hearted joke for a room of Data Scientists\"}\n",
        "  ]"
      ],
      "metadata": {
        "id": "X0pnhE0xijDc"
      },
      "id": "X0pnhE0xijDc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quant_config=BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "Qj3ft5XIixSr"
      },
      "id": "Qj3ft5XIixSr",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer =AutoTokenizer.from_pretrained(LLAMA)\n"
      ],
      "metadata": {
        "id": "sqInNip2ixJa"
      },
      "id": "sqInNip2ixJa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XVtBr8jTiw81"
      },
      "id": "XVtBr8jTiw81",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "",
      "name": ""
    },
    "language_info": {
      "name": ""
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}